{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0624a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "import json\n",
    "import openreview\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pdfplumber\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['OPENREVIEW_USERNAME'] = 'ruishich@stanford.edu'\n",
    "os.environ['OPENREVIEW_PASSWORD'] = 'Crs20010314!'\n",
    "\n",
    "client = openreview.api.OpenReviewClient(\n",
    "    baseurl='https://api2.openreview.net',\n",
    "    username=os.environ['OPENREVIEW_USERNAME'],\n",
    "    password=os.environ['OPENREVIEW_PASSWORD'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033bb58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 11672 submissions for ICLR.cc/2025/Conference/-/Submission\n"
     ]
    }
   ],
   "source": [
    "# Fetch all ICLR 2025 submissions (same as in 00_Get_PDF_url.ipynb)\n",
    "iclr_invitation = \"ICLR.cc/2025/Conference/-/Submission\"\n",
    "submissions = client.get_all_notes(invitation=iclr_invitation)\n",
    "print(f\"Retrieved {len(submissions)} submissions for {iclr_invitation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81a2fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value(field):\n",
    "    \"\"\"Handle OpenReview fields which are often dicts with a 'value' key.\"\"\"\n",
    "    if isinstance(field, dict):\n",
    "        return field.get(\"value\")\n",
    "    return field\n",
    "\n",
    "\n",
    "def get_content_value(content: dict, key: str):\n",
    "    if content is None:\n",
    "        return None\n",
    "    if key not in content:\n",
    "        return None\n",
    "    return extract_value(content[key])\n",
    "\n",
    "\n",
    "def get_submission_title(submission):\n",
    "    content = submission.content or {}\n",
    "    if \"title\" not in content:\n",
    "        return None\n",
    "    return get_content_value(content, \"title\")\n",
    "\n",
    "def extract_rating_from_review(content: dict):\n",
    "    \"\"\"Extract the numeric/text rating from a review content dict.\n",
    "\n",
    "    ICLR forms sometimes rename the field (e.g. overall_score, overall_assessment).\n",
    "    We first try common names, then fall back to any key containing\n",
    "    \"rating\" or \"score\".\n",
    "    \"\"\"\n",
    "    if not content:\n",
    "        return None\n",
    "\n",
    "    # Most likely field names\n",
    "    for k in [\"recommendation\", \"overall_assessment\", \"overall_score\", \"rating\"]:\n",
    "        if k in content:\n",
    "            return get_content_value(content, k)\n",
    "\n",
    "    # Fallback: any key that looks like a rating/score\n",
    "    for k in content.keys():\n",
    "        kl = k.lower()\n",
    "        if \"rating\" in kl or \"score\" in kl:\n",
    "            return get_content_value(content, k)\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_decision_for_forum(notes_in_forum):\n",
    "    \"\"\"Look up the decision for a given forum, given its notes.\n",
    "\n",
    "    Strategy: scan the notes and return the value of any 'decision' field.\n",
    "    \"\"\"\n",
    "    for n in notes_in_forum:\n",
    "        content = n.content or {}\n",
    "        for k in [\"decision\", \"Decision\"]:\n",
    "            if k in content:\n",
    "                return get_content_value(content, k)\n",
    "\n",
    "    # Optional: handle any special desk-reject style fields if they appear\n",
    "    for n in notes_in_forum:\n",
    "        content = n.content or {}\n",
    "        if \"desk_reject\" in content:\n",
    "            return get_content_value(content, \"desk_reject\")\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "412f11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting human reviews: 100%|██████████| 11672/11672 [41:32<00:00,  4.68it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46748"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for submission in tqdm(submissions, desc=\"Collecting human reviews\"):\n",
    "    forum_id = submission.forum\n",
    "    paper_id = submission.id\n",
    "    title = get_submission_title(submission)\n",
    "\n",
    "    # All notes (reviews, decisions, etc.) attached to this submission\n",
    "    forum_notes = client.get_all_notes(forum=forum_id)\n",
    "\n",
    "    # Use notes list here\n",
    "    decision = get_decision_for_forum(forum_notes)\n",
    "\n",
    "    # Filter to review notes (their invitations list contains 'Official_Review')\n",
    "    review_notes = []\n",
    "    for n in forum_notes:\n",
    "        invitations = getattr(n, \"invitations\", None) or []\n",
    "        if any(\"Official_Review\" in inv for inv in invitations):\n",
    "            review_notes.append(n)\n",
    "\n",
    "    for review in review_notes:\n",
    "        content = review.content or {}\n",
    "\n",
    "        reviewer_id = None\n",
    "        if \"reviewer_id\" in content:\n",
    "            reviewer_id = get_content_value(content, \"reviewer_id\")\n",
    "        else:\n",
    "            sigs = review.signatures or []\n",
    "            if sigs:\n",
    "                reviewer_id = sigs[0]\n",
    "\n",
    "        row = {\n",
    "            \"paper_forum\": forum_id,\n",
    "            \"paper_id\": paper_id,\n",
    "            \"title\": title,\n",
    "            \"decision\": decision,\n",
    "            \"review_id\": review.id,\n",
    "            \"reviewer_id\": reviewer_id,\n",
    "            \"rating\": extract_rating_from_review(content),\n",
    "            \"summary\": get_content_value(content, \"summary\"),\n",
    "            \"strengths\": get_content_value(content, \"strengths\"),\n",
    "            \"weaknesses\": get_content_value(content, \"weaknesses\"),\n",
    "            \"questions\": get_content_value(content, \"questions\"),\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02139819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews shape: (46748, 11)\n"
     ]
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame(rows)\n",
    "print(\"Reviews shape:\", reviews_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7827faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8727, 11520, 0.7575520833333333)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct manuscripts with at least one non-null decision\n",
    "papers_with_decision = (\n",
    "    reviews_df\n",
    "    .loc[reviews_df[\"decision\"].notna(), \"paper_id\"]\n",
    "    .nunique()\n",
    ")\n",
    "total_papers_in_reviews = reviews_df[\"paper_id\"].nunique()\n",
    "papers_with_decision, total_papers_in_reviews, papers_with_decision / total_papers_in_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8d52ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total manuscripts with reviews: 11520\n",
      "Manuscripts with a decision: 8727\n",
      "Manuscripts WITHOUT a decision (neglected): 2793\n",
      "Fraction neglected: 0.24244791666666668\n"
     ]
    }
   ],
   "source": [
    "df_with_decision = (\n",
    "    reviews_df\n",
    "    .loc[reviews_df[\"decision\"].notna()]\n",
    "    .drop(columns=[\"rating\"])\n",
    ")\n",
    "\n",
    "total_papers = reviews_df[\"paper_id\"].nunique()\n",
    "papers_with_decision = df_with_decision[\"paper_id\"].nunique()\n",
    "papers_without_decision = total_papers - papers_with_decision\n",
    "\n",
    "print(\"Total manuscripts with reviews:\", total_papers)\n",
    "print(\"Manuscripts with a decision:\", papers_with_decision)\n",
    "print(\"Manuscripts WITHOUT a decision (neglected):\", papers_without_decision)\n",
    "print(\"Fraction neglected:\", papers_without_decision / total_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56a8868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_decision.to_csv(\n",
    "    \"ICLR2025_human_reviews_with_decision.csv\",\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_MINIMAL,  # or csv.QUOTE_ALL\n",
    "    escapechar=\"\\\\\",            # used only if needed\n",
    ")\n",
    "\n",
    "reviews_df.to_csv(\n",
    "    \"ICLR2025_human_reviews.csv\",\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_MINIMAL,  # or csv.QUOTE_ALL\n",
    "    escapechar=\"\\\\\",            # used only if needed\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-abm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
